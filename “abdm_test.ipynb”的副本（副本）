{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"“abdm_test.ipynb”的副本","provenance":[{"file_id":"1kwSo5V-20wcGdhx9VDVn20jAVdEa4H1R","timestamp":1581607741644}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WVaFiIMlPsYP","colab_type":"code","cellView":"both","outputId":"5884c367-393b-4cd0-d085-5b37125705b9","executionInfo":{"status":"ok","timestamp":1580877107510,"user_tz":-480,"elapsed":829,"user":{"displayName":"张斌","photoUrl":"","userId":"06289499096436170536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AkaWsRDGLBEU","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"fC3UrUUMLBuR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZpool670HQ7","colab_type":"code","outputId":"fe808bb9-a4df-447d-e1cd-2fdf48d1b4c0","executionInfo":{"status":"ok","timestamp":1580877115625,"user_tz":-480,"elapsed":8916,"user":{"displayName":"张斌","photoUrl":"","userId":"06289499096436170536"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["!pip install foolbox==2.0.0\n","import torch\n","import torchvision.datasets as datasets\n","import os\n","import foolbox\n","import torchvision.models as models\n","import numpy as np\n","import cv2\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","BATCH_SIZE = 64\n","datapath = '/content/drive/My Drive/Colab Notebooks/abdm_test/ImageNet'\n","traindir = os.path.join(datapath, 'train_old')\n","labeldir = '/content/drive/My Drive/Colab Notebooks/abdm_test/ImageNet/class_to_idx.txt'\n","\n","#数据初始化\n","train_dataset = datasets.ImageFolder(\n","    traindir,\n","    transforms.Compose([\n","#         transforms.Resize(224),\n","       transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","   #      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","    #                 \t     std=[0.229, 0.224, 0.225])\n","    ])\n",")\n","\n","\n","# train_loader = torch.utils.data.DataLoader(\n","#     train_dataset, batch_size=BATCH_SIZE, shuffle=False,\n","#     num_workers=1, pin_memory=True, sampler=None)\n","#resnet101模型调用\n","resnet101 = models.resnet101(pretrained=True).eval()\n","if torch.cuda.is_available():\n","    resnet101 = resnet101.cuda()\n","else:\n","    print('===============')\n","mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n","std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n","#生成对抗模型\n","fmodel = foolbox.models.PyTorchModel(\n","    resnet101, bounds=(0, 1), num_classes=1000, preprocessing=(mean, std))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: foolbox==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox==2.0.0) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from foolbox==2.0.0) (2.21.0)\n","Requirement already satisfied: GitPython in /usr/local/lib/python3.6/dist-packages (from foolbox==2.0.0) (3.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox==2.0.0) (45.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox==2.0.0) (1.17.5)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==2.0.0) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==2.0.0) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==2.0.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==2.0.0) (2019.11.28)\n","Requirement already satisfied: gitdb2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from GitPython->foolbox==2.0.0) (2.0.6)\n","Requirement already satisfied: smmap2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from gitdb2>=2.0.0->GitPython->foolbox==2.0.0) (2.0.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EQ86B1Re0HS7","colab_type":"code","outputId":"69734d0c-f76a-428d-d9d8-4b1489d0d5a1","executionInfo":{"status":"ok","timestamp":1580877184216,"user_tz":-480,"elapsed":4338,"user":{"displayName":"张斌","photoUrl":"","userId":"06289499096436170536"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from scipy import ndimage\n","import tensorflow as tf\n","import sys\n","sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/abdm_test')\n","from abdm.abdm import ABDM\n","transform = transforms.Compose([transforms.ToTensor()])\n","\n","img_id=[]        #ori images ID list\n","img_ori=[]       #ori images list\n","img_adv=[]       #adv images list\n","img_label=[]     #ori images labels list\n","abdm_image=[]     #abdm images list  \n","\n","wrong_oriimg=0\n","right_advimg=0\n","wrong_advimg=0\n","right_abdmimg=0\n","wrong_abdmimg=0\n","for classes in range(0,20):\n","  times=200\n","  img_id=[]        #ori images ID list\n","  img_ori=[]       #ori images list\n","  img_adv=[]       #adv images list\n","  img_label=[]     #ori images labels list\n","  abdm_image=[]     #abdm images list  \n","\n","  wrong_oriimg=0\n","  right_advimg=0\n","  wrong_advimg=0\n","  right_abdmimg=0\n","  wrong_abdmimg=0\n","  for num in range(10):\n","    count=200*classes+num\n","    print(\"num: %d\" %num)\n","    image, target = train_dataset[count]\n","    print(\"图片原始大小\")\n","    print(image.shape)\n","    image = image.unsqueeze(0)\n","    image= np.array(image)\n","    print(\"image得大小\")\n","    print(image.shape)\n","    target=np.array([target,])\n","    print(\"***************************************************************\")\n","    #计算原模型的识别率，和图片的标签\n","    print('predicted class', np.argmax(fmodel.forward(image)),', ground truth class',target)\n","    tempclass1=int(np.argmax(fmodel.forward(image)))\n","    tempclass2=int(target)\n","    if(tempclass1!=tempclass2):\n","        #原模型错误识别的次数\n","        wrong_oriimg=wrong_oriimg+1\n","        continue\n","\n","    attack = foolbox.attacks.DeepFoolLinfinityAttack(fmodel, distance=foolbox.distances.Linf)   \n","    #attack = foolbox.attacks.FGSM(fmodel)\n","    #attack = foolbox.attacks.DeepFoolAttack(fmodel, distance=foolbox.distances.Linfinity)\n","    #attack = foolbox.attacks.DeepFoolAttack(fmodel, distance=foolbox.distances.MSE)\n","    #attack = foolbox.attacks.PGD(fmodel, distance=foolbox.distances.Linfinity)\n","    #attack = foolbox.attacks.AdditiveGaussianNoiseAttack(fmodel, distance=foolbox.distances.Linfinity)\n","\n","    #对抗样本生成\n","    adversarial = attack(image, target, unpack=True)\n","\n","    #测试攻击的准确率\n","    try:\n","        #对抗样本的识别标签\n","        print('adversarial class', np.argmax(fmodel.forward(adversarial)))\n","    except:\n","        #对抗样本攻击原模型失败个数 \n","        wrong_advimg=wrong_advimg+1\n","        print('error')\n","        continue\n","    else:\n","        #对抗样本攻击原模型成功个数\n","        right_advimg=right_advimg+1\n","        #print('adversarial class', np.argmax(fmodel.forward(adversarial)))\n","\n","    #===============abdm start (0.0)=========================================\n","    im=adversarial\n","    print(\"adversarial的大小\")\n","    print(im.shape)\n","\n","    im = im.reshape(3,224,224)\n","\n","    #tensor化,将图片转为(224,224,3)\n","    im = transform(im).numpy()\n","    im = transform(im).numpy()\n","    image_show=im\n","    #im=im.resize(3,224,224)\n","    print('ori image shape is :',im.shape)\n","    print(\"===========================================================\")\n","    im = im.reshape(1, 224, 224, 3)\n","    im = im.astype('float32')\n","    #print('img-over')\n","    out_size = (224, 224)\n","    batch = np.append(im, im, axis=0)\n","    batch = np.append(batch, im, axis=0)\n","    num_batch = 3 \n","    x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n","    x = tf.cast(batch, 'float32')\n","    print('begin---')\n","    with tf.variable_scope('spatial_transformer_0'):\n","        n_fc = 6\n","        w_fc1 = tf.Variable(tf.Variable(tf.zeros([224 * 224 * 3, n_fc]), name='W_fc1'))\n","        initial = np.array([[0.5, 0, 0], [0, 0.5, 0]])\n","        initial = initial.astype('float32')\n","        initial = initial.flatten()  #把数据降到一维\n","        b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')   \n","        h_fc1 = tf.matmul(tf.zeros([num_batch, 224 * 224 * 3]), w_fc1) + b_fc1\n","        print(\"输出奇怪的东西\")\n","        print(x, h_fc1, out_size)\n","        h_trans = ABDM(x, h_fc1, out_size)\n","    sess = tf.Session()\n","    sess.run(tf.global_variables_initializer())\n","    y = sess.run(h_trans, feed_dict={x: batch})\n","    abdmimg_temp=transform(y[0]).numpy()\n","    print(\"abdmimg_temp的shape:\")\n","    print(abdmimg_temp.shape)\n","    abdmimg_temp=abdmimg_temp.reshape(1,3,224,224)\n","    #print(type(abdmimg_temp))\n","    print(abdmimg_temp.shape)\n","\n","    #ABDM识别的标签\n","    adv_class=int(np.argmax(fmodel.forward(abdmimg_temp)))\n","    orilabel=int(target)\n","    #ABDM识别的标签\n","    print('abdmimg_temp class', np.argmax(fmodel.forward(abdmimg_temp)))\n","    print(\"防御图片的大小：\")\n","    print(abdmimg_temp.shape)\n","    #图片的原始标签\n","    print('ori class', orilabel)\n","\n","\n","    #防御成功\n","    if(adv_class==orilabel):\n","        # put images and labels into list\n","\n","        img_ori.append(image) #原图片\n","        img_adv.append(adversarial) #对抗图片\n","        img_label.append(target) #原始label\n","        img_id.append(count) #第i张图片的下标\n","        abdm_image.append(abdmimg_temp) #防御图片\n","        print(len(img_id)) #图片集合的大小\n","        right_abdmimg=right_abdmimg+1 #正确防御图片张数\n","    else:\n","        print('can not use this img')\n","        wrong_abdmimg=wrong_abdmimg+1 #防御失败图片张数\n","        continue\n","    print(\"***************************************************************\")\n","    \n","          \n","  ori_right=(times-wrong_oriimg)/times #原模型识别正确率\n","  adv_right=(wrong_oriimg+wrong_advimg)/times #原模型\n","  adv_wrong=(wrong_advimg)/times #对抗样本攻击原模型失败个数\n","  abdm_right=right_abdmimg/times #整体正确防御的概率(正确防御图片的张数/总测试次数)\n","  #abdm_right2=right_abdmimg/(right_abdmimg+wrong_abdmimg) #在正确生成对抗样本的集合中，防御正确概率【正确防御图片的张数/（正确防御图片的张数+防御失败图片的张数）】\n","  print(\"=======================*******************************************************========================\")\n","  print('clean image accuracy:  %.2f%%' % (ori_right * 100))\n","  print('adv image accuracy:  %.2f%%' % (adv_right * 100))\n","  print('adv_wrong:',adv_wrong)\n","  print('times:',times)\n","  print('right_abdmimg:',right_abdmimg)\n","  print('wrong_abdmimg:',wrong_abdmimg)\n","  print('abdm image accuracy:  %.2f%%' % (abdm_right * 100 ))      \n","  #print('abdm image accuracy:  %.2f%%' % (abdm_right2 * 100 ))\n","  print(\"=======================*******************************************************========================\")  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 11 , ground truth class [12]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 11 , ground truth class [12]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 11 , ground truth class [12]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 11 , ground truth class [12]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 11 , ground truth class [12]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 12 , ground truth class [13]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 13 , ground truth class [14]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 14 , ground truth class [15]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 15 , ground truth class [16]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 16 , ground truth class [17]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 19 , ground truth class [17]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 17 , ground truth class [18]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n","num: 0\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 1\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 2\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 3\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 4\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 18 , ground truth class [19]\n","num: 5\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 19 , ground truth class [20]\n","num: 6\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 19 , ground truth class [20]\n","num: 7\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 19 , ground truth class [20]\n","num: 8\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 19 , ground truth class [20]\n","num: 9\n","图片原始大小\n","torch.Size([3, 224, 224])\n","image得大小\n","(1, 3, 224, 224)\n","***************************************************************\n","predicted class 19 , ground truth class [20]\n","=======================*******************************************************========================\n","clean image accuracy:  95.00%\n","adv image accuracy:  5.00%\n","adv_wrong: 0.0\n","times: 200\n","right_abdmimg: 0\n","wrong_abdmimg: 0\n","abdm image accuracy:  0.00%\n","=======================*******************************************************========================\n"],"name":"stdout"}]}]}