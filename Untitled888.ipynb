{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled888.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM/ESNd+CcWYqomyAK+EndE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MS-1k2h_CsWI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"b4d0b7d4-024b-4e9f-e3cb-4e2a9a876dff","executionInfo":{"status":"ok","timestamp":1582715654387,"user_tz":-480,"elapsed":110309,"user":{"displayName":"韩雨薇","photoUrl":"","userId":"06310742109257259100"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RMJr9nrcDEpm","colab_type":"code","outputId":"6a3f092a-6952-41eb-a671-c2a20ff6cfaa","executionInfo":{"status":"ok","timestamp":1582715668929,"user_tz":-480,"elapsed":11980,"user":{"displayName":"韩雨薇","photoUrl":"","userId":"06310742109257259100"}},"colab":{"base_uri":"https://localhost:8080/","height":485}},"source":["!pip install foolbox==1.8.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting foolbox==1.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/6d/31f6bbd461f3276288b9bd9c0cf6d93e01231e5da2133b250e23f7df6566/foolbox-1.8.0.tar.gz (239kB)\n","\r\u001b[K     |█▍                              | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox==1.8.0) (1.17.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox==1.8.0) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox==1.8.0) (45.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from foolbox==1.8.0) (2.21.0)\n","Collecting GitPython\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==1.8.0) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==1.8.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==1.8.0) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox==1.8.0) (2.8)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f5/8f84b3bf9d94bdf2454a302f2fa375832b53660ea532586b8a55ff16ae9a/gitdb-4.0.2-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n","\u001b[?25hCollecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/35/d2/27777ab463cd44842c78305fa8097dfba0d94768abbb7e1c4d88f1fa1a0b/smmap-3.0.1-py2.py3-none-any.whl\n","Building wheels for collected packages: foolbox\n","  Building wheel for foolbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for foolbox: filename=foolbox-1.8.0-cp36-none-any.whl size=262064 sha256=bd1c73393b520a00bb123ac5090e14115e94e216d22430ab49a745069e7c484d\n","  Stored in directory: /root/.cache/pip/wheels/d7/e7/c8/153284a6e5e5c3fd4da42a8453175b45e2e185e8b5a09ced06\n","Successfully built foolbox\n","Installing collected packages: smmap, gitdb, GitPython, foolbox\n","Successfully installed GitPython-3.1.0 foolbox-1.8.0 gitdb-4.0.2 smmap-3.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nk0FZ_OUDHdm","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import time\n","import os\n","import argparse\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn.init as init\n","import foolbox\n","from scipy import ndimage\n","import tensorflow as tf\n","import sys\n","sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/GTSRB')\n","# 超参数设置\n","EPOCH = 50   #遍历数据集次数\n","pre_epoch = 0  # 定义已经遍历数据集的次数\n","BATCH_SIZE = 128      #批处理尺寸(batch_size)\n","\n","\n","# 准备数据集并预处理\n","transform_train = transforms.Compose([\n","    # transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n","    # transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n","    # transforms.ToTensor(),\n","    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n","    transforms.Resize([32,32]),\n","    transforms.ToTensor(),\n","])\n","\n","transform_test = transforms.Compose([\n","    # transforms.ToTensor(),\n","    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    transforms.Resize([32,32]),\n","    transforms.ToTensor(),\n","])\n","'''\n","trainset = torchvision.datasets.CIFAR10(root='/content/drive/My Drive/Colab Notebooks/ADP/data', train=True, download=True, transform=transform_train) #训练数据集\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n","\n","testset = torchvision.datasets.CIFAR10(root='/content/drive/My Drive/Colab Notebooks/ADP/data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n","'''\n","\n","data_dir=\"/content/drive/My Drive/Colab Notebooks/GTSRB\"\n","Testing_datasets = datasets.ImageFolder(root=os.path.join(data_dir,\"Testing\"),transform=transform_test)      \n","testloader = torch.utils.data.DataLoader(dataset=Testing_datasets,batch_size=1,shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTTWlSYkDNlS","colab_type":"code","colab":{}},"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","    def resnet_train(self,device,accuracy):\n","        LR = 0.1        #学习率\n","        initepoch = 0\n","        # 定义损失函数和优化方式\n","        optimizer = optim.SGD(self.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","        path = \"/content/drive/My Drive/Colab Notebooks/Resnet/ResNet50_0.tar\"\n","        best_acc = 85  #2 初始化best test accuracy\n","        print(\"Start Training, Resnet-20!\")  # 定义遍历数据集的次数\n","        if os.path.exists(path) is not True:\n","            criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n","            optimizer = optim.SGD(self.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","        else:\n","            checkpoint = torch.load(path)\n","            self.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            initepoch = checkpoint['epoch']\n","            criterion = checkpoint['criterion']\n","\n","        for epoch in range(initepoch, EPOCH):\n","            timestart = time.time()\n","            print('\\nEpoch: %d' % (epoch + 1))\n","            net.train()\n","            sum_loss = 0.0\n","            correct = 0.0\n","            total = 0.0\n","            if epoch>=5:\n","                LR = 0.01\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","            if epoch>=15:\n","                LR = 0.001\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","                \n","            if epoch>=25:\n","                LR = 0.0001\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","            if epoch>=35:\n","                LR = 0.00001\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","            print(\"进入数据\")\n","            for i, data in enumerate(trainloader, 0):\n","                # 准备数据\n","                length = len(trainloader)\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                # print(\"train_labels\")\n","                # print(labels)\n","                optimizer.zero_grad()\n","                # forward + backward\n","                outputs = self(inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                sum_loss += loss.item()\n","            torch.save({'epoch':epoch,\n","                                    'model_state_dict':net.state_dict(),\n","                                    'optimizer_state_dict':optimizer.state_dict(),\n","                                    'criterion':criterion\n","                                    },path)\n","            print('epoch %d cost %3f sec' %(epoch,time.time()-timestart))\n","            print(\"Waiting Test!\")\n","            with torch.no_grad():\n","              correct = 0\n","              total = 0\n","              for data in testloader:\n","                  net.eval()\n","                  images, labels = data\n","                  images, labels = images.to(device), labels.to(device)\n","                  outputs = net(images)\n","                  # 取得分最高的那个类 (outputs.data的索引号)\n","                  _, predicted = torch.max(outputs.data, 1)\n","                  total += labels.size(0)\n","                  correct += (predicted == labels).sum()\n","            accuracy.append(100.0 * correct / total)\n","            print(accuracy)\n","            print('测试分类准确率为：%.3f%%' % (100. * correct / total))\n","            print('Saving model......')\n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohu2D_f_DZR_","colab_type":"code","colab":{}},"source":["class ADP(nn.Module):\n","  def __init__(self):\n","    super(ADP, self).__init__()\n","    #         adp_layer\n","    self.conv1_adp = nn.Conv2d(3, 32, kernel_size=5,padding=2)\n","    self.BN02_adp =nn.BatchNorm2d(32)\n","    self.conv11_adp = nn.Conv2d(32, 64, kernel_size=5,padding=2)\n","    self.BN03_adp =nn.BatchNorm2d(64)\n","    self.conv12_adp = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n","    self.BN04_adp =nn.BatchNorm2d(64)\n","    \n","    self.convo1_adp = nn.Conv2d(64, 8, kernel_size=1)\n","    self.fc1_adp = nn.Linear(512, 1024)\n","    self.BN0_adp =nn.BatchNorm1d(1024)\n","    self.longLSTM_adp = nn.LSTMCell(512,512) \n","    \n","    self.conv21_adp = nn.Conv2d(3,16, kernel_size=5,padding=2)\n","    self.BN1_adp =nn.BatchNorm2d(16)\n","    self.conv22_adp = nn.Conv2d(16, 32, kernel_size=5,padding=2)\n","    self.BN2_adp =nn.BatchNorm2d(32)\n","    self.conv23_adp = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n","    self.BN22_adp =nn.BatchNorm2d(32)\n","    self.shortLSTM_adp = nn.LSTMCell(512,512) \n","    self.MemorySize_adp=512\n","\n","  def add_adp(self,x):\n","    cuda = torch.cuda.is_available()\n","    if cuda:\n","      longMemory_adp=(Variable(torch.zeros(x.size(0), self.MemorySize_adp).cuda()),\n","            Variable(torch.zeros(x.size(0), self.MemorySize_adp).cuda()))\n","      shortMemory_adp=(Variable(torch.zeros(x.size(0), self.MemorySize_adp).cuda()),\n","            Variable(torch.zeros(x.size(0), self.MemorySize_adp).cuda()))  \n","    else:\n","      longMemory_adp=(Variable(torch.zeros(x.size(0), self.MemorySize_adp)),\n","            Variable(torch.zeros(x.size(0), self.MemorySize_adp)))\n","      shortMemory_adp=(Variable(torch.zeros(x.size(0), self.MemorySize_adp)),\n","            Variable(torch.zeros(x.size(0), self.MemorySize_adp)))\n","    for i in range(4):\n","      x1=x.clone()\n","      xc= F.relu(F.max_pool2d(self.BN02_adp(self.conv1_adp(x1)), 2))\n","      xc= F.relu(F.max_pool2d(self.BN03_adp(self.conv11_adp(xc)), 2))\n","      xc= F.relu(self.BN04_adp(self.conv12_adp(xc)))\n","      xc=self.convo1_adp(xc)\n","      xr=xc.view(-1,512)\n","      longMemory_adp=self.longLSTM_adp(xr,longMemory_adp)            \n","      lt=F.relu(self.BN0_adp(self.fc1_adp(longMemory_adp[0])))\n","      lt=lt.view(-1,32,32)\n","      lt=torch.stack([lt,lt,lt],dim=1) \n","      x0=Variable(x.data,requires_grad=False)\n","      xI=torch.mul(lt,x0)                       \n","      xc= F.relu(F.max_pool2d(self.BN1_adp(self.conv21_adp(xI)),2))\n","      xc= F.relu(F.max_pool2d(self.BN2_adp(self.conv22_adp(xc)),2))\n","      xc= F.relu(F.max_pool2d(self.BN22_adp(self.conv23_adp(xc)),2))\n","      xc=xc.view(-1,512)\n","      shortMemory_adp=self.shortLSTM_adp(xc,shortMemory_adp)\n","      longMemory_adp=self.longLSTM_adp(shortMemory_adp[0],longMemory_adp)\n","    return xI\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNetADP(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNetADP, self).__init__()\n","        self.adp=ADP()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.adp.add_adp(x)\n","        out = F.relu(self.bn1(self.conv1(out)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","    def resnet_train(self,device,accuracy):\n","        LR = 0.01        #学习率\n","        initepoch = 0\n","        # 定义损失函数和优化方式\n","        optimizer = optim.SGD(self.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","        path = \"/content/drive/My Drive/Colab Notebooks/GTSRB/Resnet/ResNet50ADP_0.tar\"\n","        best_acc = 85  #2 初始化best test accuracy\n","        print(\"Start Training, Resnet-20!\")  # 定义遍历数据集的次数\n","        if os.path.exists(path) is not True:\n","            criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n","            optimizer = optim.SGD(self.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","        else:\n","            checkpoint = torch.load(path)\n","            self.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            initepoch = checkpoint['epoch']\n","            criterion = checkpoint['criterion']\n","\n","        for epoch in range(initepoch, EPOCH):\n","            timestart = time.time()\n","            print('\\nEpoch: %d' % (epoch + 1))\n","            net.train()\n","            sum_loss = 0.0\n","            correct = 0.0\n","            total = 0.0\n","            if epoch>=5 and epoch<15:\n","                LR = 0.01\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","            if epoch>=15 and epoch<25:\n","                LR = 0.001\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","                \n","            if epoch>=25 and epoch<35:\n","                LR = 0.0001\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","            if epoch>=35:\n","                LR = 0.0001\n","                optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","            print(\"进入数据\")\n","            for i, data in enumerate(trainloader, 0):\n","                # 准备数据\n","                length = len(trainloader)\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                # print(\"train_labels\")\n","                # print(labels)\n","                optimizer.zero_grad()\n","                # forward + backward\n","                outputs = self(inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                sum_loss += loss.item()\n","            torch.save({'epoch':epoch,\n","                                    'model_state_dict':net.state_dict(),\n","                                    'optimizer_state_dict':optimizer.state_dict(),\n","                                    'criterion':criterion\n","                                    },path)\n","            print('epoch %d cost %3f sec' %(epoch,time.time()-timestart))\n","            print(\"Waiting Test!\")\n","            with torch.no_grad():\n","              correct = 0\n","              total = 0\n","              for data in testloader:\n","                  net.eval()\n","                  images, labels = data\n","                  images, labels = images.to(device), labels.to(device)\n","                  outputs = net(images)\n","                  # 取得分最高的那个类 (outputs.data的索引号)\n","                  _, predicted = torch.max(outputs.data, 1)\n","                  total += labels.size(0)\n","                  correct += (predicted == labels).sum()\n","            accuracy.append(100.0 * correct / total)\n","            print(accuracy)\n","            print('测试分类准确率为：%.3f%%' % (100. * correct / total))\n","            print('Saving model......')\n","     \n","    def resnet_test(self,device):\n","        print(\"Waiting Test!\")\n","        with torch.no_grad():\n","            correct = 0\n","            total = 0\n","            for batch_idx, data in enumerate(testloader):\n","                net.eval()\n","                images, labels = data\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = self(images)\n","                # 取得分最高的那个类 (outputs.data的索引号)\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum()\n","                # if(batch_idx>=1):\n","                #   break\n","            print('测试分类准确率为：%.3f%%' % (100 * correct / total))\n","            print(batch_idx)\n","            print(correct)\n","            print(total)\n","            acc = 100. * correct / total\n","            # 将每次测试结果实时写入acc.txt文件中\n","            print('Saving model......',\"correct:\",correct,\" total:\",total)\n","        # print(np.argmax(outputs.cpu()))\n","\n","\n","def ResNet18ADP():\n","    return ResNetADP(BasicBlock, [2,2,2,2])\n","\n","def ResNet34ADP():\n","    return ResNetADP(BasicBlock, [3,4,6,3])\n","\n","def ResNet50ADP():\n","    return ResNetADP(Bottleneck, [3,4,6,3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKkha-jDDv-P","colab_type":"code","outputId":"1433df3e-5ef9-47d9-fa50-10bd71e2009c","executionInfo":{"status":"error","timestamp":1582711308098,"user_tz":-480,"elapsed":2275,"user":{"displayName":"韩雨薇","photoUrl":"","userId":"06310742109257259100"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def ABDM(input_fmap, theta, out_dims=None, **kwargs):\n","\n","    # grab input dimensions\n","    B = tf.shape(input_fmap)[0]\n","    H = tf.shape(input_fmap)[1]\n","    W = tf.shape(input_fmap)[2]\n","\n","    # reshape theta to (B, 2, 3)\n","    theta = tf.reshape(theta, [B, 2, 3])\n","\n","    # generate grids of same size or upsample/downsample if specified\n","    if out_dims:\n","        out_H = out_dims[0]\n","        out_W = out_dims[1]\n","        batch_grids = affine_grid_generator(out_H, out_W, theta)\n","    else:\n","        batch_grids = affine_grid_generator(H, W, theta)\n","\n","    x_s = batch_grids[:, 0, :, :]\n","    y_s = batch_grids[:, 1, :, :]\n","\n","    # sample input with grid to get output\n","    out_fmap = bilinear_sampler(input_fmap, x_s, y_s)\n","\n","    return out_fmap\n","\n","\n","def get_pixel_value(img, x, y):\n","\n","    shape = tf.shape(x)\n","    batch_size = shape[0]\n","    height = shape[1]\n","    width = shape[2]\n","\n","    batch_idx = tf.range(0, batch_size)\n","    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n","    b = tf.tile(batch_idx, (1, height, width))\n","\n","    indices = tf.stack([b, y, x], 3)\n","\n","    return tf.gather_nd(img, indices)\n","\n","\n","def affine_grid_generator(height, width, theta):\n","\n","    num_batch = tf.shape(theta)[0]\n","\n","    # create normalized 2D grid\n","    x = tf.linspace(-1.0, 1.0, width)\n","    y = tf.linspace(-1.0, 1.0, height)\n","    x_t, y_t = tf.meshgrid(x, y)\n","\n","    # flatten\n","    x_t_flat = tf.reshape(x_t, [-1])\n","    y_t_flat = tf.reshape(y_t, [-1])\n","\n","    # reshape to [x_t, y_t , 1] - (homogeneous form)\n","    ones = tf.ones_like(x_t_flat)\n","    sampling_grid = tf.stack([x_t_flat, y_t_flat, ones])\n","\n","    # repeat grid num_batch times\n","    sampling_grid = tf.expand_dims(sampling_grid, axis=0)\n","    sampling_grid = tf.tile(sampling_grid, tf.stack([num_batch, 1, 1]))\n","\n","    # cast to float32 (required for matmul)\n","    theta = tf.cast(theta, 'float32')\n","    sampling_grid = tf.cast(sampling_grid, 'float32')\n","\n","    # transform the sampling grid - batch multiply\n","    batch_grids = tf.matmul(theta, sampling_grid)\n","    # batch grid has shape (num_batch, 2, H*W)\n","\n","    # reshape to (num_batch, H, W, 2)\n","    batch_grids = tf.reshape(batch_grids, [num_batch, 2, height, width])\n","\n","    return batch_grids\n","\n","\n","def bilinear_sampler(img, x, y):\n","\n","    H = tf.shape(img)[1]\n","    W = tf.shape(img)[2]\n","    max_y = tf.cast(H - 1, 'int32')\n","    max_x = tf.cast(W - 1, 'int32')\n","    zero = tf.zeros([], dtype='int32')\n","\n","    # rescale x and y to [0, W-1/H-1]\n","    x = tf.cast(x, 'float32')\n","    y = tf.cast(y, 'float32')\n","    x = 0.5 * ((x + 1.0) * tf.cast(max_x-1, 'float32'))\n","    y = 0.5 * ((y + 1.0) * tf.cast(max_y-1, 'float32'))\n","\n","    # grab 4 nearest corner points for each (x_i, y_i)\n","    x0 = tf.cast(tf.floor(x), 'int32')\n","    x1 = x0 + 1\n","    y0 = tf.cast(tf.floor(y), 'int32')\n","    y1 = y0 + 1\n","\n","    # clip to range [0, H-1/W-1] to not violate img boundaries\n","    x0 = tf.clip_by_value(x0, zero, max_x)\n","    x1 = tf.clip_by_value(x1, zero, max_x)\n","    y0 = tf.clip_by_value(y0, zero, max_y)\n","    y1 = tf.clip_by_value(y1, zero, max_y)\n","\n","    # get pixel value at corner coords\n","    Ia = get_pixel_value(img, x0, y0)\n","    Ib = get_pixel_value(img, x0, y1)\n","    Ic = get_pixel_value(img, x1, y0)\n","    Id = get_pixel_value(img, x1, y1)\n","\n","    # recast as float for delta calculation\n","    x0 = tf.cast(x0, 'float32')\n","    x1 = tf.cast(x1, 'float32')\n","    y0 = tf.cast(y0, 'float32')\n","    y1 = tf.cast(y1, 'float32')\n","\n","    # calculate deltas\n","    wa = (x1-x) * (y1-y)\n","    wb = (x1-x) * (y-y0)\n","    wc = (x-x0) * (y1-y)\n","    wd = (x-x0) * (y-y0)\n","\n","    # add dimension for addition\n","    wa = tf.expand_dims(wa, axis=3)\n","    wb = tf.expand_dims(wb, axis=3)\n","    wc = tf.expand_dims(wc, axis=3)\n","    wd = tf.expand_dims(wd, axis=3)\n","\n","    # compute output\n","    out = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n","\n","    return out\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","model_ResNet50 = ResNet50()\n","model_ResNet50 = model_ResNet50.to(device).eval()\n","path='/content/drive/My Drive/Colab Notebooks/GTSRB/ResNet50zero_3.tar'\n","checkpoint = torch.load(path,map_location=device)\n","model_ResNet50.load_state_dict(checkpoint['model_state_dict'])\n","\n","model_ResNet50ADP = ResNet50ADP()\n","model_ResNet50ADP = model_ResNet50ADP.to(device).eval()\n","path='/content/drive/My Drive/Colab Notebooks/GTSRB/ResNet50ADP_10.tar'\n","checkpoint = torch.load(path,map_location=device)\n","model_ResNet50ADP.load_state_dict(checkpoint['model_state_dict'])\n","\n","fmodel_ResNet50 = foolbox.models.PyTorchModel(model_ResNet50, bounds=(0, 1), num_classes=10, preprocessing=(0, 1))\n","fmodel_ResNet50ADP = foolbox.models.PyTorchModel(model_ResNet50ADP, bounds=(0, 1), num_classes=10, preprocessing=(0, 1))\n","\n","count=20 #图片测试张数\n","total=0 #总的图片数\n","num1=0 #fmodel预测正确数\n","num2=0 #对抗样本数\n","num3=0 #ADP恢复数\n","num4=0 #ABDM恢复数\n","\n","label_number=0\n","original_rate=[]\n","adv_rate=[]\n","adp_rate=[]\n","abdm_rate=[]\n","for batch_idx, data in enumerate(testloader):\n","  image, label = data\n","  image=image.squeeze(0).data.numpy()\n","  label = label.numpy()[0]\n","  if(total==count): #总的图片数\n","    print(\"原始图片识别精度：%.3f\"%(num1/count))\n","    print(\"对抗样本识别精度：%.3f\"%(1-num2/count))\n","    print(\"ADP处理识别精度：%.3f\"%(num3/count)) \n","    print(\"ABDM处理识别精度：%.3f\" %(num4/count))\n","    print(\"=======================================\")\n","    original_rate.append(num1/count)\n","    adv_rate.append(1-num2/count)\n","    adp_rate.append(num3/count)\n","    abdm_rate.append(num4/count)\n","    num3 = num4 = 0\n","    num1 = num2 = 0\n","    total = 0\n","    label_number = label_number + 1\n","    \n","\n","  if(label==label_number and total<count):\n","    total+=1 #总的图片数\n","    print(\"原图类别:\",label)\n","    if(np.argmax(fmodel_ResNet50.predictions(image))==label): #fmodel预测正确数\n","      num1+=1\n","    #attack_ResNet50=foolbox.attacks.FGSM(fmodel_ResNet50,distance=foolbox.distances.Linf) #攻击方式\n","    attack_ResNet50=foolbox.attacks.CarliniWagnerL2Attack(fmodel_ResNet50,distance=foolbox.distances.Linf)\n","    adversarial_ResNet50=attack_ResNet50(input_or_adv=image,label=label,unpack=False) #生成对抗样本\n","    adv_ResNet50=adversarial_ResNet50.image\n","    if(adv_ResNet50 is not None):\n","      num2+=1 #对抗样本数\n","      adv_ResNet50_class = np.argmax(fmodel_ResNet50.predictions(adv_ResNet50))\n","      print(\"对抗样本类别:\",adv_ResNet50_class)\n","      \n","      #ADP\n","      adv_ResNet50ADP_class = np.argmax(fmodel_ResNet50ADP.predictions(adv_ResNet50))\n","      print(\"ADP对对抗样本进行防御产生的类别:\",adv_ResNet50ADP_class)\n","      if(adv_ResNet50ADP_class == label):\n","        num3+=1\n","      \n","      #ABDM\n","      im = adv_ResNet50#原模型对抗样本\n","      transform = transforms.Compose([transforms.ToTensor()])\n","      im = transform(im).numpy()\n","      im = transform(im).numpy()\n","      im = im.reshape(1, 32, 32, 3)\n","      im = im.astype('float32')\n","      out_size = (32, 32)\n","      batch = np.append(im, im, axis=0)\n","      batch = np.append(batch, im, axis=0)\n","      num_batch = 3 \n","      x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n","      x = tf.cast(batch, 'float32')\n","      with tf.variable_scope('spatial_transformer_0'):\n","          n_fc = 6\n","          w_fc1 = tf.Variable(tf.Variable(tf.zeros([32 * 32 * 3, n_fc]), name='W_fc1'))\n","          initial = np.array([[0.9, 0, 0], [0, 0.9, 0]])\n","          initial = initial.astype('float32')\n","          initial = initial.flatten()  #把数据降到一维\n","          b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')   \n","          h_fc1 = tf.matmul(tf.zeros([num_batch, 32 * 32 * 3]), w_fc1) + b_fc1\n","          h_trans = ABDM(x, h_fc1, out_size)\n","      sess = tf.Session()\n","      sess.run(tf.global_variables_initializer())\n","      y = sess.run(h_trans, feed_dict={x: batch})\n","      abdmimg_temp=transform(y[0]).numpy()\n","      adv3_label = np.argmax(fmodel_ResNet50.predictions(abdmimg_temp))\n","      print(\"ABDM对对抗样本进行防御产生的类别:\",adv3_label)\n","      if(adv3_label==label):\n","        num4+=1\n","      \n","    else:\n","      #ADP\n","      adv_ResNet50ADP_class = np.argmax(fmodel_ResNet50ADP.predictions(image))\n","      print(\"ADP对原图进行防御产生的类别:\",adv_ResNet50ADP_class)\n","      if(adv_ResNet50ADP_class == label):\n","        num3+=1\n","      \n","      \n","      #ABDM\n","      im = image#原图\n","      transform = transforms.Compose([transforms.ToTensor()])\n","      im = transform(im).numpy()\n","      im = transform(im).numpy()\n","      im = im.reshape(1, 32, 32, 3)\n","      im = im.astype('float32')\n","      out_size = (32, 32)\n","      batch = np.append(im, im, axis=0)\n","      batch = np.append(batch, im, axis=0)\n","      num_batch = 3 \n","      x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n","      x = tf.cast(batch, 'float32')\n","      with tf.variable_scope('spatial_transformer_0'):\n","          n_fc = 6\n","          w_fc1 = tf.Variable(tf.Variable(tf.zeros([32 * 32 * 3, n_fc]), name='W_fc1'))\n","          initial = np.array([[0.9, 0, 0], [0, 0.9, 0]])\n","          initial = initial.astype('float32')\n","          initial = initial.flatten()  #把数据降到一维\n","          b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')   \n","          h_fc1 = tf.matmul(tf.zeros([num_batch, 32 * 32 * 3]), w_fc1) + b_fc1\n","          h_trans = ABDM(x, h_fc1, out_size)\n","      sess = tf.Session()\n","      sess.run(tf.global_variables_initializer())\n","      y = sess.run(h_trans, feed_dict={x: batch})\n","      abdmimg_temp=transform(y[0]).numpy()\n","      adv3_label = np.argmax(fmodel_ResNet50.predictions(abdmimg_temp))\n","      print(\"ABDM对原图进行防御产生的类别:\",adv3_label)\n","      if(adv3_label==label):\n","        num4+=1\n","\n","print(original_rate)\n","print(adv_rate)\n","print(adp_rate)\n","print(abdm_rate)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n","原图类别: 0\n","对抗样本类别: 3\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n","  warnings.warn('Not running the attack because the original input'\n"],"name":"stderr"},{"output_type":"stream","text":["ADP对对抗样本进行防御产生的类别: 3\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","ABDM对对抗样本进行防御产生的类别: 3\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 7\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 7\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 3\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 9\n","原图类别: 0\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 3\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 3\n","原图类别: 0\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 3\n","ABDM对对抗样本进行防御产生的类别: 3\n","原图类别: 0\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 0\n","原图类别: 0\n","对抗样本类别: 9\n","ADP对对抗样本进行防御产生的类别: 0\n","ABDM对对抗样本进行防御产生的类别: 0\n","原始图片识别精度：0.800\n","对抗样本识别精度：0.000\n","ADP处理识别精度：0.750\n","ABDM处理识别精度：0.450\n","=======================================\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 3\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 1\n","对抗样本类别: 2\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 1\n","原始图片识别精度：0.950\n","对抗样本识别精度：0.000\n","ADP处理识别精度：0.900\n","ABDM处理识别精度：0.900\n","=======================================\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 7\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 0\n","ADP对对抗样本进行防御产生的类别: 1\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 3\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 1\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 1\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n","对抗样本类别: 6\n","ADP对对抗样本进行防御产生的类别: 2\n","ABDM对对抗样本进行防御产生的类别: 2\n","原图类别: 2\n"],"name":"stdout"}]}]}